# import os, json, requests
# from glob import glob
#
# DETAIL_URL = "https://api.editorup.com/api/v1/resource/templates/{id}"
# headers = {
#     "Accept": "application/json, text/plain, */*",
#     "Origin": "https://app.editorup.com",
#     "Referer": "https://app.editorup.com/",
#     "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"
# }
#
# # ğŸ“ æœ¬åœ° JSON æ–‡ä»¶ç›®å½•
# LOCAL_JSON_DIR = "./mobanData_20250611_111058"
# # LOCAL_JSON_DIR = "./mobanData_20250611_120422"
#
# IGNORED_KEYS = {
#     "/data/dimension",
#     "/data/height",
#     "/data/width",
#     "/data/updatedAt",
#     "/msg"
# }
#
# PRINT_KEYS = [
#     "/data/title",
#     "/data/priceStrategy",
#     "/data/snapshot",
#     "/data/tags",
#     "/data/author",
#     "/data/data/pages",
#     "/data/data/orders"
# ]
#
# def load_json(path):
#     with open(path, encoding="utf-8") as f:
#         return json.load(f)
#
# def get_by_path(data, path):
#     keys = path.strip("/").split("/")
#     for k in keys:
#         if isinstance(data, dict):
#             data = data.get(k)
#         else:
#             return None
#     return data
#
# def find_differences(local, remote, prefix=""):
#     diffs = []
#     if isinstance(local, dict) and isinstance(remote, dict):
#         keys = set(local.keys()) | set(remote.keys())
#         for k in keys:
#             path = f"{prefix}/{k}"
#             if path in IGNORED_KEYS:
#                 continue
#             lv = local.get(k)
#             rv = remote.get(k)
#             diffs.extend(find_differences(lv, rv, path))
#     elif isinstance(local, list) and isinstance(remote, list):
#         if local != remote:
#             diffs.append((prefix, local, remote))
#     else:
#         if local != remote:
#             diffs.append((prefix, local, remote))
#     return diffs
#
# def print_field(data, path):
#     val = get_by_path(data, path)
#     print(f"     â€¢ {path} : {repr(val)}")
#
# # â—ç›®å½•æ£€æŸ¥
# if not os.path.isdir(LOCAL_JSON_DIR):
#     print(f"âŒ é”™è¯¯ï¼šç›®å½•ä¸å­˜åœ¨ - {LOCAL_JSON_DIR}")
#     exit(1)
#
# files = glob(os.path.join(LOCAL_JSON_DIR, "*.json"))
# if not files:
#     print(f"âŒ é”™è¯¯ï¼šç›®å½•ä¸­æœªæ‰¾åˆ°ä»»ä½• JSON æ–‡ä»¶ - {LOCAL_JSON_DIR}")
#     exit(1)
#
# # ğŸ” å¼€å§‹å¯¹æ¯”
# print(f"\nğŸ“‚ å¾…å¯¹æ¯”æ–‡ä»¶æ•°ï¼š{len(files)}\n")
#
# pass_cnt, fail_cnt = 0, 0
# fail_detail = []
#
# for idx, filepath in enumerate(files, 1):
#     local_json = load_json(filepath)
#     tpl_id = get_by_path(local_json, "/data/id")
#     title = get_by_path(local_json, "/data/title")
#     try:
#         r = requests.get(DETAIL_URL.format(id=tpl_id), headers=headers, timeout=10)
#         r.raise_for_status()
#         remote_json = r.json()
#     except Exception as e:
#         print(f"{idx:>3}/{len(files)} âŒ è¯·æ±‚å¤±è´¥ - ID:{tpl_id} - {e}")
#         fail_cnt += 1
#         continue
#
#     diffs = find_differences(local_json, remote_json)
#
#     if diffs:
#         fail_cnt += 1
#         print(f"{idx:>3}/{len(files)} âŒ ä¸é€šè¿‡ - ID:{tpl_id}")
#         for path, local_val, remote_val in diffs[:10]:
#             print(f"     â€¢ {path}")
#             print(f"         æœ¬åœ°å€¼ : {repr(local_val)}")
#             print(f"         çº¿ä¸Šå€¼ : {repr(remote_val)}")
#         if len(diffs) > 10:
#             print(f"     â€¦ å…¶ä½™ {len(diffs)-10} æ¡å·®å¼‚çœç•¥")
#         fail_detail.append({
#             "id": tpl_id,
#             "title": title,
#             "diffs": diffs[:10]
#         })
#     else:
#         pass_cnt += 1
#         print(f"{idx:>3}/{len(files)} âœ… é€šè¿‡   - ID:{tpl_id}")
#         for path in PRINT_KEYS:
#             print_field(local_json, path)
#
# # âœ… æ±‡æ€»
# print("\n================  æ±‡  æ€»  ================ ")
# print(f"æ€»æ¨¡æ¿æ•°   : {len(files)}")
# print(f"é€šè¿‡æ•°é‡   : {pass_cnt}")
# print(f"ä¸é€šè¿‡æ•°é‡ : {fail_cnt}")
#
# if fail_detail:
#     print("\nğŸš¨ ä¸é€šè¿‡æ¨¡æ¿è¯¦æƒ…ï¼š")
#     for item in fail_detail:
#         tpl_id = item['id']
#         print(f"\nâŒ æ¨¡æ¿æ ‡é¢˜: {item['title']}")
#         print(f"   æ¨¡æ¿ ID : {tpl_id}")
#         for path, lv, rv in item["diffs"]:
#             field = path.strip("/").split("/")[-1]
#             page_id, element_id = extract_ids_from_path(path)
#             prefix = f"[æ¨¡æ¿ID:{tpl_id}]"
#             if page_id:
#                 prefix += f" [é¡µé¢ID:{page_id}]"
#             if element_id:
#                 prefix += f" [ç´ æID:{element_id}]"
#             print(f"  {prefix} å·®å¼‚å­—æ®µ: {path}")
#             print(f"  {prefix} {field} : æœ¬åœ°æ•°æ® {repr(lv)} â‰  æ¥å£è¿”å› {repr(rv)}")
#






import os, json, requests
from glob import glob

DETAIL_URL = "https://api.editorup.com/api/v1/resource/templates/{id}"
headers = {
    "Accept": "application/json, text/plain, */*",
    "Origin": "https://app.editorup.com",
    "Referer": "https://app.editorup.com/",
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"
}

# ğŸ“ æœ¬åœ° JSON æ–‡ä»¶ç›®å½•
LOCAL_JSON_DIR = "./mobanData_20250612_101229"


IGNORED_KEYS = {
    "/data/dimension",
    "/data/height",
    "/data/width",
    "/data/updatedAt",
    "/msg"
}

PRINT_KEYS = [
    "/data/title",
    "/data/priceStrategy",
    "/data/snapshot",
    "/data/tags",
    "/data/author",
    "/data/data/pages",
    "/data/data/orders"
]

def load_json(path):
    with open(path, encoding="utf-8") as f:
        return json.load(f)

def get_by_path(data, path):
    keys = path.strip("/").split("/")
    for k in keys:
        if isinstance(data, dict):
            data = data.get(k)
        else:
            return None
    return data

def find_differences(local, remote, prefix=""):
    diffs = []
    if isinstance(local, dict) and isinstance(remote, dict):
        keys = set(local.keys()) | set(remote.keys())
        for k in keys:
            path = f"{prefix}/{k}"
            if path in IGNORED_KEYS:
                continue
            lv = local.get(k)
            rv = remote.get(k)
            diffs.extend(find_differences(lv, rv, path))
    elif isinstance(local, list) and isinstance(remote, list):
        if local != remote:
            diffs.append((prefix, local, remote))
    else:
        if local != remote:
            diffs.append((prefix, local, remote))
    return diffs

def print_field(data, path):
    val = get_by_path(data, path)
    print(f"     â€¢ {path} : {repr(val)}")

def extract_ids_from_path(path):
    # path: "/data/data/pages/{pageId}/elements/{elementId}/..."
    parts = path.strip("/").split("/")
    page_id = None
    element_id = None
    try:
        if "pages" in parts:
            idx = parts.index("pages")
            page_id = parts[idx + 1]
        if "elements" in parts:
            idx = parts.index("elements")
            element_id = parts[idx + 1]
    except IndexError:
        pass
    return page_id, element_id

# â—ç›®å½•æ£€æŸ¥
if not os.path.isdir(LOCAL_JSON_DIR):
    print(f"âŒ é”™è¯¯ï¼šç›®å½•ä¸å­˜åœ¨ - {LOCAL_JSON_DIR}")
    exit(1)

files = glob(os.path.join(LOCAL_JSON_DIR, "*.json"))
if not files:
    print(f"âŒ é”™è¯¯ï¼šç›®å½•ä¸­æœªæ‰¾åˆ°ä»»ä½• JSON æ–‡ä»¶ - {LOCAL_JSON_DIR}")
    exit(1)

# ğŸ” å¼€å§‹å¯¹æ¯”
print(f"\nğŸ“‚ å¾…å¯¹æ¯”æ–‡ä»¶æ•°ï¼š{len(files)}\n")

pass_cnt, fail_cnt = 0, 0
fail_detail = []

for idx, filepath in enumerate(files, 1):
    local_json = load_json(filepath)
    tpl_id = get_by_path(local_json, "/data/id")
    title = get_by_path(local_json, "/data/title")
    try:
        r = requests.get(DETAIL_URL.format(id=tpl_id), headers=headers, timeout=10)
        r.raise_for_status()
        remote_json = r.json()
    except Exception as e:
        print(f"{idx:>3}/{len(files)} âŒ è¯·æ±‚å¤±è´¥ - ID:{tpl_id} - {e}")
        fail_cnt += 1
        continue

    diffs = find_differences(local_json, remote_json)

    if diffs:
        fail_cnt += 1
        print(f"{idx:>3}/{len(files)} âŒ ä¸é€šè¿‡ - ID:{tpl_id}")
        for path, local_val, remote_val in diffs[:10]:
            page_id, element_id = extract_ids_from_path(path)
            prefix = f"[æ¨¡æ¿ID:{tpl_id}]"
            if page_id:
                prefix += f" [é¡µé¢ID:{page_id}]"
            if element_id:
                prefix += f" [ç´ æID:{element_id}]"
            field = path.strip("/").split("/")[-1]
            print(f"  {prefix} å·®å¼‚å­—æ®µ: {path}")
            print(f"  {prefix} {field} : æœ¬åœ°æ•°æ® {repr(local_val)} â‰  æ¥å£è¿”å› {repr(remote_val)}")
        if len(diffs) > 10:
            print(f"     â€¦ å…¶ä½™ {len(diffs)-10} æ¡å·®å¼‚çœç•¥")
        fail_detail.append({
            "id": tpl_id,
            "title": title,
            "diffs": diffs[:10]
        })
    else:
        pass_cnt += 1
        print(f"{idx:>3}/{len(files)} âœ… é€šè¿‡   - ID:{tpl_id}")
        for path in PRINT_KEYS:
            print_field(local_json, path)

# âœ… æ±‡æ€»
print("\n================  æ±‡  æ€»  ================ ")
print(f"æ€»æ¨¡æ¿æ•°   : {len(files)}")
print(f"é€šè¿‡æ•°é‡   : {pass_cnt}")
print(f"ä¸é€šè¿‡æ•°é‡ : {fail_cnt}")

if fail_detail:
    print("\nğŸš¨ ä¸é€šè¿‡æ¨¡æ¿è¯¦æƒ…ï¼š")
    for item in fail_detail:
        tpl_id = item['id']
        print(f"\nâŒ æ¨¡æ¿æ ‡é¢˜: {item['title']}")
        print(f"  æ¨¡æ¿ ID: {tpl_id}")
        for path, lv, rv in item["diffs"]:
            page_id, element_id = extract_ids_from_path(path)
            prefix = f"[æ¨¡æ¿ID:{tpl_id}]"
            if page_id:
                prefix += f" [é¡µé¢ID:{page_id}]"
            if element_id:
                prefix += f" [ç´ æID:{element_id}]"
            field = path.strip("/").split("/")[-1]
            print(f"  ID å®šä½: {prefix}")
            print(f"  å·®å¼‚ä½ç½®: {path}")
            print(f"  å·®å¼‚æ•°æ®: æœ¬åœ°æ•°æ® {repr(lv)} â‰  æ¥å£è¿”å› {repr(rv)}")


